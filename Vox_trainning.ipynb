{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bdfed9-858b-470a-a497-32b497db187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from pre_process import form_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8cc34-ff08-466f-9f5e-45e8393e95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INT16_MAX = 32767\n",
    "SAMPLE_RATE = 16000\n",
    "FRAME_SIZE = int(SAMPLE_RATE * 0.025)\n",
    "NFFT = 512 \n",
    "NFILT = 40\n",
    "N_SPEAKER = 32\n",
    "pre_emphasis = 0.97\n",
    "\n",
    "spk_list = os.listdir(\"vox/vox1_dev_wav\")\n",
    "utterance = {}\n",
    "emphasized_data = []\n",
    "validation_dataset = []\n",
    "validation_data = []\n",
    "validation_label = []\n",
    "train_data = []\n",
    "train_label = []\n",
    "enrollment_dataset = []\n",
    "verification_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88439ca6-0891-4380-98b1-79cd2d350862",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid, speaker in enumerate(spk_list[0:N_SPEAKER]):\n",
    "    if not speaker.startswith(\".\"):\n",
    "        utterance[speaker] = {}\n",
    "        path = \"vox/vox1_dev_wav/\" + speaker\n",
    "        folders = os.listdir(path)\n",
    "        utterance[speaker]['files'] = []\n",
    "        for folder in folders:\n",
    "            if not folder.startswith(\".\"):\n",
    "                path = \"vox/vox1_dev_wav/\" + speaker + \"/\" + folder\n",
    "                files = os.listdir(path)\n",
    "                for file in files:\n",
    "                    if not file.startswith(\".\"):\n",
    "                        utterance[speaker]['files'].append(folder + \"/\" + file)\n",
    "\n",
    "        for count in range(10):\n",
    "            file_path = \"vox/vox1_dev_wav/\" + speaker + \"/\" + utterance[speaker]['files'].pop(0)\n",
    "            try:\n",
    "                _, data = wavfile.read(file_path)         # requires tons of memory with many spekaers\n",
    "                emphasized_signal = np.append(data[0], data[1:] - pre_emphasis * data[:-1])\n",
    "                if count < 5:\n",
    "                    emphasized_data.append((emphasized_signal,pid))\n",
    "                elif count < 10:\n",
    "                    validation_dataset.append((emphasized_signal,pid))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "for entry in emphasized_data:\n",
    "    form_input_data(entry, train_data, train_label)\n",
    "for entry in validation_dataset:\n",
    "    form_input_data(entry, validation_data, validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa1d69-8e53-4bfd-9d99-9f46720b42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainning_data.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([train_data, train_label, validation_data, validation_label], f)\n",
    "with open('utterance_list.pkl', 'wb') as f:\n",
    "    pickle.dump([utterance, spk_list], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad03a95-7487-4944-9f28-291e8aed4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(NFILT*41,))\n",
    "dense1 = keras.layers.Dense(256, kernel_regularizer='l2', activation='relu')(inputs)\n",
    "dense2 = keras.layers.Dense(256, kernel_regularizer='l2', activation='relu')(dense1)\n",
    "dense3 = keras.layers.Dense(256, kernel_regularizer='l2', activation='relu')(dense2)\n",
    "drop_out1 = keras.layers.Dropout(0.5)(dense3)\n",
    "dense4 = keras.layers.Dense(256, kernel_regularizer='l2', activation='relu')(drop_out1)\n",
    "drop_out2 = keras.layers.Dropout(0.5)(dense4)\n",
    "outputs = keras.layers.Dense(N_SPEAKER, activation='softmax')(drop_out2)\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef27ec1-dfb0-4d18-a06e-c6b0fe9cba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e28f5-c58f-439f-b8ff-d10f153d5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(np.array(train_data), np.array(train_label), epochs=50, shuffle=True, validation_data=(np.array(validation_data),np.array(validation_label)))\n",
    "model.save(\"saved_model/my_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
