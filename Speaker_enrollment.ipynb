{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55326854-2b54-47e5-83b9-f968d05c2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pre_process import form_input_data\n",
    "pre_emphasis = 0.97\n",
    "pid = 5 # pick 5 as a random speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4bfe07-59e2-450a-ad44-824aaf3894ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1640)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               420096    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                8224      \n",
      "=================================================================\n",
      "Total params: 625,696\n",
      "Trainable params: 625,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"saved_model/my_model\")\n",
    "model.summary()\n",
    "layer_name = 'dropout_1'\n",
    "intermediate_layer_model = keras.models.Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b0f5d8-c47e-4ca8-a75d-8d14545c9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('utterance_list.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    utterance, spk_list = pickle.load(f)\n",
    "enrollment_dataset = []\n",
    "for speaker in spk_list[0:1]:\n",
    "    for count in range(5):\n",
    "        file_path = \"vox/vox1_dev_wav/\" + speaker + \"/\" + utterance[speaker]['files'].pop(0)\n",
    "        _, data = wavfile.read(file_path)         # requires tons of memory with many spekaers\n",
    "        emphasized_signal = np.append(data[0], data[1:] - pre_emphasis * data[:-1])\n",
    "        enrollment_dataset.append((emphasized_signal,pid))\n",
    "\n",
    "    enrollment_data = []\n",
    "    enrollment_label = []\n",
    "    d_utterance_list = []\n",
    "    \n",
    "    for entry in enrollment_dataset:\n",
    "        enrollment_data.clear()\n",
    "        enrollment_label.clear()\n",
    "        form_input_data(entry, enrollment_data, enrollment_label)\n",
    "        intermediate_output = intermediate_layer_model.predict(np.array(enrollment_data))\n",
    "        d_utterance = np.zeros(256)\n",
    "        for out in intermediate_output:\n",
    "            d_utterance += out/sum(out)\n",
    "        d_utterance_list.append(d_utterance) # Saving the utterance d-vector for future uncertainty measure\n",
    "    d_model = np.zeros(256)\n",
    "    for vector in d_utterance_list:\n",
    "        d_model += vector\n",
    "    d_model = d_model/len(d_utterance_list)\n",
    "    filename = 'd-vector/' + speaker + '.pkl'\n",
    "    with open(filename, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([d_utterance_list, d_model], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5104c8d9-d8e8-49eb-ab30-00754d09048a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21084/748279600.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# same speaker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mspeaker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspk_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../VCTK-Corpus/wav48/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mspeaker\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mutterance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'files'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0memphasized_signal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpre_emphasis\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mevaluation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# pre-process evaluation utterance\n",
    "# same speaker\n",
    "speaker = spk_list[pid]\n",
    "_, data = \"vox/vox1_dev_wav/\" + speaker + \"/\" + utterance[speaker]['files'].pop(0)\n",
    "emphasized_signal = np.append(data[0], data[1:] - pre_emphasis * data[:-1])\n",
    "evaluation_data = []\n",
    "evaluation_label = []\n",
    "form_input_data((emphasized_signal,pid), evaluation_data, evaluation_label)\n",
    "intermediate_output = intermediate_layer_model.predict(np.array(evaluation_data))\n",
    "d_eva = np.zeros(256)\n",
    "for out in intermediate_output:\n",
    "    d_eva += out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbcefec3-2154-4146-ab76-957eccff3f1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_utterance_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21084/2231631883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvector\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_utterance_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_eva\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd_utterance_list' is not defined"
     ]
    }
   ],
   "source": [
    "for n,vector in enumerate(d_utterance_list):\n",
    "    print(np.corrcoef(vector,d_eva)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ae39de-3a35-4081-ace9-6731c895048e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.91814532]\n",
      " [0.91814532 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(d_model,d_eva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afba9eae-620d-4d5e-b9a1-f91a0eeb8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process evaluation utterance\n",
    "# different speaker\n",
    "speaker = spk_list[45]\n",
    "_, data = \"vox/vox1_dev_wav/\" + speaker + \"/\" + utterance[speaker]['files'].pop(0)\n",
    "emphasized_signal = np.append(data[0], data[1:] - pre_emphasis * data[:-1])\n",
    "evaluation_data = []\n",
    "evaluation_label = []\n",
    "form_input_data((emphasized_signal,pid), evaluation_data, evaluation_label)\n",
    "intermediate_output = intermediate_layer_model.predict(np.array(evaluation_data))\n",
    "d_eva = np.zeros(256)\n",
    "for out in intermediate_output:\n",
    "    d_eva += out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f33213e-0a58-4506-9093-faaf65a1a2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.41615877]\n",
      " [0.41615877 1.        ]]\n",
      "[[1.         0.51021078]\n",
      " [0.51021078 1.        ]]\n",
      "[[1.         0.52906224]\n",
      " [0.52906224 1.        ]]\n",
      "[[1.         0.44008616]\n",
      " [0.44008616 1.        ]]\n",
      "[[1.        0.3603832]\n",
      " [0.3603832 1.       ]]\n"
     ]
    }
   ],
   "source": [
    "for n,vector in enumerate(d_utterance_list):\n",
    "    print(np.corrcoef(vector,d_eva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ac0f55-a68d-4618-84d2-2012de02f3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.47151495]\n",
      " [0.47151495 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(d_model,d_eva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2254229-5f8c-47ba-a5c3-5f4d9b899e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
