{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55326854-2b54-47e5-83b9-f968d05c2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pre_process import form_input_data\n",
    "pre_emphasis = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4bfe07-59e2-450a-ad44-824aaf3894ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1640)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               420096    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                8224      \n",
      "=================================================================\n",
      "Total params: 625,696\n",
      "Trainable params: 625,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"saved_model/my_model\")\n",
    "model.summary()\n",
    "layer_name = 'dropout_1'\n",
    "intermediate_layer_model = keras.models.Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b0f5d8-c47e-4ca8-a75d-8d14545c9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('utterance_list.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    utterance, spk_list = pickle.load(f)\n",
    "enrollment_dataset = []\n",
    "pid = 5 # pick 5 as a random speaker\n",
    "speaker = spk_list[pid]\n",
    "for count in range(5):\n",
    "    file_path = \"../VCTK-Corpus/wav48/\" + speaker + \"/\" + utterance[speaker]['files'].pop(0)\n",
    "    _, data = wavfile.read(file_path)         # requires tons of memory with many spekaers\n",
    "    emphasized_signal = np.append(data[0], data[1:] - pre_emphasis * data[:-1])\n",
    "    enrollment_dataset.append((emphasized_signal,pid))\n",
    "\n",
    "enrollment_data = []\n",
    "enrollment_label = []\n",
    "d_utterance_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0cb0ad9-43d7-4c52-aa1e-7bd96c0763f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in enrollment_dataset:\n",
    "    enrollment_data.clear()\n",
    "    enrollment_label.clear()\n",
    "    form_input_data(entry, enrollment_data, enrollment_label)\n",
    "    intermediate_output = intermediate_layer_model.predict(np.array(enrollment_data))\n",
    "    d_utterance = np.zeros(256)\n",
    "    for out in intermediate_output:\n",
    "        d_utterance += out/sum(out)\n",
    "    d_utterance_list.append(d_utterance) # Saving the utterance d-vector for future uncertainty measure\n",
    "    \n",
    "d_model = np.zeros(256)\n",
    "for vector in d_utterance_list:\n",
    "    d_model += vector\n",
    "d_model = d_model/len(d_utterance_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5104c8d9-d8e8-49eb-ab30-00754d09048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process evaluation utterance\n",
    "# same speaker\n",
    "_, data = wavfile.read(\"../VCTK-Corpus/wav48/p230/p230_280.wav\")\n",
    "emphasized_signal = np.append(data[0], data[1:] - pre_emphasis * data[:-1])\n",
    "evaluation_data = []\n",
    "evaluation_label = []\n",
    "form_input_data((emphasized_signal,pid), evaluation_data, evaluation_label)\n",
    "intermediate_output = intermediate_layer_model.predict(np.array(evaluation_data))\n",
    "d_eva = np.zeros(256)\n",
    "for out in intermediate_output:\n",
    "    d_eva += out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbcefec3-2154-4146-ab76-957eccff3f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.89614739]\n",
      " [0.89614739 1.        ]]\n",
      "[[1.         0.88919356]\n",
      " [0.88919356 1.        ]]\n",
      "[[1.         0.88289639]\n",
      " [0.88289639 1.        ]]\n",
      "[[1.         0.91427108]\n",
      " [0.91427108 1.        ]]\n",
      "[[1.         0.90908563]\n",
      " [0.90908563 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "for n,vector in enumerate(d_utterance_list):\n",
    "    print(np.corrcoef(vector,d_eva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ae39de-3a35-4081-ace9-6731c895048e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.91814532]\n",
      " [0.91814532 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(d_model,d_eva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afba9eae-620d-4d5e-b9a1-f91a0eeb8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process evaluation utterance\n",
    "# different speaker\n",
    "_, data = wavfile.read(\"../VCTK-Corpus/wav48/p237/p237_280.wav\")\n",
    "emphasized_signal = np.append(data[0], data[1:] - pre_emphasis * data[:-1])\n",
    "evaluation_data = []\n",
    "evaluation_label = []\n",
    "form_input_data((emphasized_signal,pid), evaluation_data, evaluation_label)\n",
    "intermediate_output = intermediate_layer_model.predict(np.array(evaluation_data))\n",
    "d_eva = np.zeros(256)\n",
    "for out in intermediate_output:\n",
    "    d_eva += out/sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f33213e-0a58-4506-9093-faaf65a1a2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.41615877]\n",
      " [0.41615877 1.        ]]\n",
      "[[1.         0.51021078]\n",
      " [0.51021078 1.        ]]\n",
      "[[1.         0.52906224]\n",
      " [0.52906224 1.        ]]\n",
      "[[1.         0.44008616]\n",
      " [0.44008616 1.        ]]\n",
      "[[1.        0.3603832]\n",
      " [0.3603832 1.       ]]\n"
     ]
    }
   ],
   "source": [
    "for n,vector in enumerate(d_utterance_list):\n",
    "    print(np.corrcoef(vector,d_eva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ac0f55-a68d-4618-84d2-2012de02f3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.47151495]\n",
      " [0.47151495 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(d_model,d_eva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2254229-5f8c-47ba-a5c3-5f4d9b899e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
